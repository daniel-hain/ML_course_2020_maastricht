---
title: 'Data Science Basics: R basics'
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    code_folding: show
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    theme: flatly
    
# knit: markdowntemplates::to_jupyter
---

```{r setup, include=FALSE}
### Generic preamble
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation

### Knitr options
knitr::opts_chunk$set(warning=FALSE,
                     message=FALSE,
                     fig.align="center"
                     )
```

# Introduction
In this session, you will learn the basic R syntax, including:

1. General syntax
2. basic operations
3. Object & data types
4. Flow controls
5. Introduction to the `tidyverse` and piping.

# Brief Introduction: Base-R

The general base-R syntax is, in contrast to other more general-purpose programming language, already very geared towards working with data. MAny slicing/dicing ect. functionalities which for instance in Python require additional libraries (eg. Pandas in Python) are in R (as a dedicated statistical pogramming language) come with R out-of-the-box. However, the traditional R syntax has during the last years been mainly replaced by the tidy-principles pushed by R.Studio and implemented in their ´tidyverse´ ecosystem.

We will not use too much base-R syntax in our time together. However, it is still important to know the basics, since there are always here and there situation where you just cannot avoid it

## Basics 

### Assignments 
 
You can assign a value to an object using `assign()`,  `<-`, or `=`.
```{r}
x <- 3         # Assignment
x              # Evaluate the expression and print result

y <- 4         # Assignment
y + 5          # Evaluation, y remains 4

z <- x + 17*y  # Assignment
z              # Evaluation

rm(z)          # Remove z: deletes the object.
# z             # Error!
```


### Value comparisons 

Comparisons return boolean values: TRUE or FALSE (often abbreviated to `T` and `F`)
```{r}
2==2  # Equality
2!=2  # Inequality
x <= y # less than or equal: "<", ">", and ">=" also work
```


### Special constants: `NA`, `NULL`, `Inf`, `-Inf`, `NaN`

`NA` indicates missing or undefined data
```{r}
5 + NA      # When used in an expression, the result is generally NA
is.na(5+NA) # Check if missing

mean(c(1, 2, NA, 4, 5)) # many functions requiring numeric vectors output  when one is included
mean(c(1, 2, NA, 4, 5), na.rm = TRUE) # Not if we provide the right argument to ignore them
```

`NULL` indicates an empty object, e.g. a null/empty list
```{r}
10 + NULL     # use returns an empty object (length zero)
is.null(NULL) # check if NULL
```

`Inf` and `-Inf` represent positive and negative infinity. They can be returned by  mathematical operations like division of a number by zero.
```{r}
5/0
is.finite(5/0) # Check if a number is finite
is.infinite(5/0) # Check if a number is infinite
```

`NaN` (Not a Number) - the result of an operation that cannot be reasonably defined 
```{r}
0/0
is.nan(0/0)
```

## Object classes

### Vectors

```{r}
v1 <- c(1, 5, 11, 33)       # Numeric vector, length 4
v1

v2 <- c("hello","world")    # Character vector, length 2 (a vector of strings)
v2

v3 <- c(TRUE, TRUE, FALSE)  # Logical vector, same as c(T, T, F)
v3
```

Combining different types of elements in one vector will coerce the elements  to the least restrictive type:
```{r}
v4 <- c(v1,v2,v3,"boo") 	# All elements turn into strings
v4
```

Element-wise operations:
```{r}
v1 + v3      # Element-wise addition (reminder: TRUE counts as 1, FALSE as 0)
v1 + 1       # Add 1 to each element
v1 * 2       # Multiply EACH element by 2 (not like real vector multiplication)
v1 + c(1,7)  # (1,7) is a vector of different length... what happens here?
```

Mathematical operations:
```{r}
sum(v1)      # The sum of all elements
mean(v1)     # The average of all elements
sd(v1)       # The standard deviation
cor(v1,v1*5) # Correlation between v1 and v1*5 
```

Logical operations:
```{r}
v1 > 2       # Each element is compared to 2, returns logical vector
v1==v2       # Are corresponding elements equivalent, returns logical vector.
v1!=v2       # Are corresponding elements *not* equivalent? Same as !(v1==v2)
(v1>2) | (v2>0)   # | is the boolean OR, returns a vector.
(v1>2) & (v2>0)   # & is the boolean AND, returns a vector.
(v1>2) || (v2>0)  # || is the boolean OR, returns a single value (if it is true at least once)
(v1>2) && (v2>0)  # && is the boolean AND, returns a single value (if it is true at least once)
```

Adressing vector elements:
```{r}
v1[3]             # third element of v1
v1[2:4]           # elements 2, to 4 of v1
v1[c(1,3)]        # elements 1 and 3 - note that your indexes are a vector
v1[c(T,T,F,F,F)]  # elements 1 and 2 - only the ones that are TRUE
v1[v1>3]          # v1>3 is a logical vector TRUE for elements >3
```

**NOTE:** If you are used to languages indexing from 0 (eg. Python), `R` will surprise you by indexing from 1.

To add more elements to a vector, simply assign them values.
```{r}
v1[6:10] <- 6:10
v1
```

We can also directly assign the vector a length:
```{r}
length(v1) <- 15 # the last 5 elements are added as missing data: NA
v1
```

### Factors

Factors are used to store categorical data.
```{r}
eye.col.v <- c("brown", "green", "brown", "blue", "blue", "blue")         #vector
eye.col.f <- factor(c("brown", "green", "brown", "blue", "blue", "blue")) #factor
eye.col.v
eye.col.f
```

`R` will identify the different levels of the factor - e.g. all distinct values. The data is stored internally as integers - each number corresponding to a factor level.

```{r}
levels(eye.col.f)  # The levels (distinct values) of the factor (categorical variable)

as.numeric(eye.col.f)  # The factor as numeric values: 1 is  blue, 2 is brown, 3 is green
as.numeric(eye.col.v)  # The character vector, however, can not be coerced to numeric

as.character(eye.col.f)  
as.character(eye.col.v) 
```


### Matrces & Arrays 

A matrix is a vector with dimensions:
```{r}
m <- rep(1, 20)   # A vector of 20 elements, all 1
dim(m) <- c(5,4)  # Dimensions set to 5 & 4, so m is now a 5x4 matrix
m
```

Create a matrix using `matrix()`:
```{r}
m <- matrix(data=1, nrow=5, ncol=4)  # same matrix as above, 5x4, full of 1s
m <- matrix(1,5,4) 			             # same matrix as above (lazy style)
dim(m)                                # What are the dimensions of m?
m
```

Create a matrix by combining vectors:
```{r}
m <- cbind(1:5, 5:1, 5:9)  # Bind 3 vectors as columns, 5x3 matrix
m <- rbind(1:5, 5:1, 5:9)  # Bind 3 vectors as rows, 3x5 matrix
m <- matrix(1:10,10,10)
m
```

Select matrix elements: 
```{r}
m[2,3]  # Matrix m, row 2, column 3 - a single cell
m[2,]   # The whole second row of m as a vector
m[,2]   # The whole second column of m as a vector
m[1:2,4:6] # submatrix: rows 1 and 2, columns 4, 5 and 6
m[-1,]     # all rows *except* the first one
```

Conditional operations
```{r}
m[1,] == m[,1]  # Are elements in row 1 equivalent to corresponding elements from column 1? 
m > 3           # A logical matrix: TRUE for m elements >3, FALSE otherwise
m[m > 3]        # Selects only TRUE elements - that is ones greater than 3
```

Other matrix manipulation
```{r}
t(m)          # Transpose m     
m %*% t(m)    # %*% does matrix multiplication
m * m         # * does element-wise multiplication
```


### Arrays: more than 2 dimensions

Created with the `array()` function:
```{r}
a <- array(data=1:18,dim=c(3,3,2)) # 3d with dimensions 3x3x2
a <- array(1:18,c(3,3,2))          # the same array
a
```

Since arrays have 3 dimensions, also a 3rd element can be used for slicing&dicinhg.
```{r}
a[1,3,2]
```


### Lists  

Lists are collections of objects (e.g. of strings, vectors, matrices, other lists, etc.)
```{r}
l1 <- list(boo=v1,foo=v2,moo=v3,zoo="Animals!")  # A list with four components
l2 <- list(v1,v2,v3,"Animals!")

l3 <- list()
l4 <- NULL

```

```{r}
l1["boo"]      # Access boo: this returns a list.
l1[["boo"]]    # Access boo: this returns the numeric vector
l1[[1]]        # Returns the first component of the list, equivalent to above.
l1[[1]][2]     # Acess the second element in the first list
l1$boo         # Named elements can be accessed using the $ operator - equivalent to [[]]
```

Add more elements to a list:
```{r}
l3[[1]] <- 11 # add an element to the empty list l3
l4[[3]] <- c(22, 23) # add a vector as element 3 in the empty list l4. 
                     # Since we added element 3, elements 1 & 2 will be generated and empty (NULL)
l1[[5]] <- "More elements!" # The list l1 had 4 elements, we're adding a 5th here.
l1[[8]] <- 1:11 # We added an 8th element, but not 6th or 7th. Those will be created empty (NULL)
l1$Something <- "A thing"  # Adds a ninth element - "A thing", named "Something"
```


### Data Frames  
The data frame is a special kind of list used for storing dataset tables. Think of rows as cases, columns as variables. Each column is a vector or factor.

Note: While base `R` uses the `data.frame`, we later when working with `tidyverse` use the `tibble` instead, which is the same but modifies some annoying behaviors of the original data type (eg. no default interpretations of strings as factors, no `rownames`. More on that later).  

Creating a dataframe:
```{r}
dfr1 <- data.frame( ID=1:4,
                    FirstName=c("Jesper","Jonas","Pernille","Helle"),
                    Female=c(F,F,T,T), 
                    Age=c(22,33,44,55) )

dfr1$FirstName   # Access the second column of dfr1. 
```

**Notice** that `R` thinks this is a categorical variable  and so it's treating it like a factor, not a character vector. You can tell `R` you don't like factors from the start using `stringsAsFactors=FALSE`. I find that annoying. The `tibble` (introduced later) does not do that.

```{r}
dfr2 <- data.frame(FirstName=c("John","Jim","Jane","Jill"), stringsAsFactors=FALSE)
dfr2$FirstName   # Success: not a factor.
```

Access elements of the data frame. Notation is `dfr[row, column]` Rows can be acessed by number or condition, columns by number or name. Alternatively, columns can be acessed by `dfr$column`
```{r}
dfr1[1,]   # First row, all columns
dfr1[,1]   # First column, all rows
dfr1$Age   # Age column, all rows
dfr1[1:2,3:4] # Rows 1 and 2, columns 3 and 4 - the gender and age of John & Jim
dfr1[c(1,3),] # Rows 1 and 3, all columns
```

Find the names of everyone over the age of 30 in the data
```{r}
dfr1[dfr1$Age>30,2]
```

Find the average age of all females in the data:
```{r}
mean (dfr1[dfr1$Female==TRUE,4])
```


## Flow Control (loops & friends)
Loops are powerful little helpers to do the same operation iterating over a number of items.

If statements: `if (condition) expr1 else expr2`
```{r}
x <- 5; y <- 10
if (x==0) y <- 0 else y <- y/x  
y
```

for loops: `for (variable in sequence) expr`
```{r}
for (i in 1:x)  { print(paste("OMG, i just counted to", i)) }
```

While loop: `while (condintion) expr`
```{r}
while (x > 0) {print(x); x <- x-1;}
```

Repeat loop: `repeat expr, use break to exit the loop`
```{r}
repeat { print(x); x <- x+1; if (x>7) break}
```

## R troubleshooting 

While I generate many (and often very creative) errors in R, there are three simple things that will most often go wrong for me. Those include: 

* Capitalization. R is case sensitive - a graph vertex named "Jack" is not the same as one named "jack". The function `rowSums` won't work as "rowsums" or "RowSums".
* Object class. While many functions are willing to take anything you throw at them, some will still surprisingly require character vector or a factor instead of a numeric vector, or a matrix instead of a data frame. Functions will also occasionally return results in an unexpected format.
* Package namespaces. Occasionally problems will arise when different packages contain functions with the same name. R may warn you about this by saying something like "The following object(s) are masked from 'package:igraph'" as you load a package. One way to deal with this is to call functions from a package explicitly using '::'. For instance, if function 'blah' is present in packages A and B, you can call A::blah

```{r}
# install.packages('dplyr')
# library(dplyr)          # load a package
# detach(package:dplyr)   # detach a package
```

```{r}
dplyr::select(dfr1, FirstName) # packagename::functionname   lets you access the namespace from packages not loaded (but installed)
```

For more advanced troubleshooting, check out `try()`, `tryCatch()`, and `debug()`. 
```{r}
?tryCatch
```

Generally, just using `?functionyouwonderabout` often solves problems. There you can review the functions arguments, inputs, outputs, syntax etc.

# R 2.0: The Tidyverse

## What is it all about?
Base `R` comes with quite some functionality for slicing and dicing data, there also exists a myriad specialized packages for more tricky data manipulation. To read others' code and example as well as to perform some special operations, you all should be able to use standard `R` syntax. 

However, the factors, the `[row, column]` syntax anhd so forth are not very comfortable and intuitive. Further, for more tricky operation such as certain aggregations etc., one has to rely on a variety of packages, which often come with an own syntax.

The good news is: The efforts of a small set of key-developers (foremost [Hadley Wickham](http://hadley.nz/)) has let to the development of the  [`tidyverse`](https://www.tidyverse.org/), an ecosystem of `R` packages particularly designed for data science applications. All packages share an underlying design philosophy, common API, grammar, and data structures. 

Among the most amazing contributions here is [`dplyr`](https://dplyr.tidyverse.org/), a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. I use `dplyr` for 90% of my data-manipulation tasks for the following reasons:

* All the underlying code is runs optimized in `C++`, making it faster than most base `R`
* It consistently unifies the grammar of data manipulation to a small set of operations, which can be flexibly combined to master almost every task
* It is designed to work neathly with the `%>%` pipe-operator of [magrittr](hhttps://magrittr.tidyverse.org/) (more on that later)
* its syntax is very similar to the logic of `SQL` and other data-management languages
* It expanded far beoyond its original 5 verbs, and now replaces most base R commands with optimized, clever, and high-performance alternatives
* It works neathly with many databases, such as `SQL` (with addon packages `DBI` and `dbplyr`)

I will not touch on all packages there, but the complete `tidyverse` covers almost all issues of data manipulation. They all operate under the same logic, are fast, and usually your best choice for almost any given problem. Particularly `dplyr` is enourmeously powerfull, and has a lot more functions than the basics I cover here. So, for every given problem, your first question (to yourself or [stackoverflow](https://stackoverflow.com/)) should be:

1: Is there a way to solve my problem in `dplyr`?
2: If not, is there another `tidyverse` package dedicated to this problem?

For the sake of illustration, I will load every package of the `tidyverse` one-by-one when we need it. However, normally I just load `library(tidyverse)` all at once, since I need a lot of these packages often anyhow

```{r}
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
```

## Tibbles

Tibbles are the `tidyverse` version of the traditional dataframe. They work in exactly the same way, only with some small differences, which are usually from a data science perspctive seen as an improvement:

1. Strings ae by default not recoded as factors
2. Rownames are dropped
3. Default print delivers  more convenient overview.

They can be created in 3 different ways.

1. Creating them from scratch with `tibble()`
3. Using explicitly the `as_tibble()` function on a table
3. When applying and `dplyr` function on a dataframe, it will automatically be converted to a tibble.

```{r}
head(iris) # a dataframe
```

```{r}
head(as_tibble(iris))
```

It is usually the prefered format for data science projects in R.

## Piping 

in traditional `R` syntax, data-manipulations are carried out one by one. For example, one would first assign a new variable `x$numbers <- 1:5`, then maybe manipulate it `x$numbers <- x$numbers * 2`, and subset it `x <- x[x$numbers > 4]`. `dplyr` makes use of `margrittr`'s pipes, written like `%>%`. 

A pipe means take the output of it's left-hand side and insert it as first input in the function on the right-hand side. Accordingly, all `dplyr` functions follow the syntax that their first input is always the data to be manipulated. Therefore, they can all be "piped".

```{r}
x <- tibble(numbers = 1:5) 
```

Lets say we want to multiply all number with 2, and THEN subset the data for observations with a number larger than 4. We could do the following

```{r}
y <- x
y[,'numbers'] <- y[,'numbers'] * 2
y <- y[y['numbers'] > 4, ]
y
```

For example, we could pipe as follows (don't worry about the other syntax yet):

```{r}
x %>%
  mutate(numbers = numbers * 2) %>%
  filter(numbers > 4)
```

It basically reads like: 

* Create a dataframe (to be precise, a `tibble`) with the variable "numbers" and assign the values 1:5.
* THEN multiply them with 2.
: THEN subset the dataframe to only rows with a nuimber value higher than 4.

It first looks not so intuitive, but it will become your second nature. Using pipes facilitates fast, reproducible and easily readable coding practices, and all of you are encouraged to go on with that.

**Note:** `%>%` pipes do not autometically assign their output to the left-hand side object, meaning the original dataset will not per se be overwritten. To do that, there are two ways:

1: Initially, assign the output to the original data with `<-`
2: Initially, use `margrittr`'s `%<>%` command, meaning: Assign and pipe.

```{r}
# This will create an output, but not change x
x %>%
  filter(numbers > 5)

# This will re-assign x
x <- x %>%
  filter(numbers > 5)
# is equivalent to
x %<>%
  filter(numbers > 5) 
```

In conclusion: The pipe basically passes on dataframe between functions in the following way:
```{r, eval = FALSE, warning = FALSE}
# Only pseudo code here, does not run
x %>% fun(na.rm = TRUE) %>%
  filter() %>%

# Is equivalent to
fun(x, na.rm = TRUE)

# While
x %<>% fun()
# Is equivalent to
x <- fun(x)
```

Piping also provides better overview over the flow of actions as compared to nested functions

```{r, eval = FALSE}
# Nested functions
went_to_bed(had_dinner(programmed_some_r(had_lunch(programmed_some_r(had_brekfast(got_up(day)))))))

# vs pipes
day %>%
  got_up() %>%
  had_breakfast() %>%
  programmed_some_r() %>%
  had_lunch() %>%
  programmed_some_r() %>%
  had_dinner() %>%
  went_to_bed()
```


## Handling special data formats

It is not part of this introductory lecture, but you soon might encounter that you have to deal with 2 common formats in some way, which are date-times (time-codes) and strings (text). When that point comes, just check the following to get started (and if necessary branch out to further sources suggested):

* **Strings:** R for Data Science (Grolemund & Wickham) [Chapter 14](https://r4ds.had.co.nz/strings.html)
* **DateTimes:** R for Data Science (Grolemund & Wickham) [Chapter 16](https://r4ds.had.co.nz/dates-and-times.html)


# Adittional Infos

## R, notebooks & markdown

While many people prefer to work with `R` scripts, computional notebooks are especially in the data science community more popular for `R` users. This is mainly don in the `Rmarkdown` format, which combines markdown markup an notation with executable code and result outputs. All the petty html notebooks i create fo you are also done in that way. For further information and to get started, check:

* Basics: R for Data Science (Grolemund & Wickham) [Chapter 27](https://r4ds.had.co.nz/r-markdown.html)
* Details: [R Markdown: The Definitive Guide (Xie, Allaire & Grolemund)](https://bookdown.org/yihui/rmarkdown/)


## R, google colab & co.

Google colab does not officially support `R` kernels. However, there is a little trick how to make `R` run with colab. 

If you want to start from scratch, do the following:

* You can simply run the `demo.ipynb` from [IRkernel Github](https://colab.research.google.com/github/IRkernel/IRkernel/blob/master/example-notebooks/Demo.ipynb)
* Make changes and then save a copy to your Google Drive.
* You can also see all 3 example notebooks [here](https://github.com/IRkernel/IRkernel/tree/master/example-notebooks).

If you already have an R-Markdown notebook:

* use the [IRkernel](https://github.com/IRkernel/IRkernel) to create a `.ipynb` out of your `.rmd`
* If you dont want to do it locally, use [this colab notebook](https://colab.research.google.com/github/SDS-AAU/SDS-master/blob/master/00_notebooks/converter_rmd_to_jupyter.ipynb) instead. Just upload the `.rmd`, run the code (alter the filename), and download the resulting `.ipynb`. This now can be uploaded to colab.

# Endnotes

### References

### Further infos

### Session Info
```{r}
sessionInfo()
````